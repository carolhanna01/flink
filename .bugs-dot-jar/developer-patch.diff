diff --git a/flink-formats/flink-orc/src/main/java/org/apache/flink/orc/vector/AbstractOrcColumnVector.java b/flink-formats/flink-orc/src/main/java/org/apache/flink/orc/vector/AbstractOrcColumnVector.java
index 3d68bc61648..61511f98bd8 100644
--- a/flink-formats/flink-orc/src/main/java/org/apache/flink/orc/vector/AbstractOrcColumnVector.java
+++ b/flink-formats/flink-orc/src/main/java/org/apache/flink/orc/vector/AbstractOrcColumnVector.java
@@ -113,7 +113,7 @@ public abstract class AbstractOrcColumnVector implements
 			case DATE:
 				return createLongVector(batchSize, dateToInternal((Date) value));
 			case TIMESTAMP_WITHOUT_TIME_ZONE:
-				return createTimestampVector(batchSize, (LocalDateTime) value);
+				return createTimestampVector(batchSize, value);
 			default:
 				throw new UnsupportedOperationException("Unsupported type: " + type);
 		}
@@ -176,20 +176,15 @@ public abstract class AbstractOrcColumnVector implements
 		return dcv;
 	}
 
-	private static TimestampColumnVector createTimestampVector(int batchSize, LocalDateTime value) {
+	private static TimestampColumnVector createTimestampVector(int batchSize, Object value) {
 		TimestampColumnVector lcv = new TimestampColumnVector(batchSize);
 		if (value == null) {
 			lcv.noNulls = false;
 			lcv.isNull[0] = true;
 			lcv.isRepeating = true;
 		} else {
-			long epochDay = value.toLocalDate().toEpochDay();
-			long nanoOfDay = value.toLocalTime().toNanoOfDay();
-
-			long millisecond = epochDay * 24 * 60 * 60 * 1000 + nanoOfDay / 1_000_000;
-			int nanoOfSecond = (int) (nanoOfDay % 1_000_000_000);
-			Timestamp timestamp = new Timestamp(millisecond);
-			timestamp.setNanos(nanoOfSecond);
+			Timestamp timestamp = value instanceof LocalDateTime ?
+				Timestamp.valueOf((LocalDateTime) value) : (Timestamp) value;
 			lcv.fill(timestamp);
 			lcv.isNull[0] = false;
 		}
diff --git a/flink-formats/flink-orc/src/main/java/org/apache/flink/orc/vector/OrcTimestampColumnVector.java b/flink-formats/flink-orc/src/main/java/org/apache/flink/orc/vector/OrcTimestampColumnVector.java
index dec2515f9fb..6917e1183da 100644
--- a/flink-formats/flink-orc/src/main/java/org/apache/flink/orc/vector/OrcTimestampColumnVector.java
+++ b/flink-formats/flink-orc/src/main/java/org/apache/flink/orc/vector/OrcTimestampColumnVector.java
@@ -22,6 +22,8 @@ import org.apache.flink.table.dataformat.SqlTimestamp;
 
 import org.apache.hadoop.hive.ql.exec.vector.TimestampColumnVector;
 
+import java.sql.Timestamp;
+
 /**
  * This column vector is used to adapt hive's TimestampColumnVector to
  * Flink's TimestampColumnVector.
@@ -39,8 +41,8 @@ public class OrcTimestampColumnVector extends AbstractOrcColumnVector implements
 	@Override
 	public SqlTimestamp getTimestamp(int i, int precision) {
 		int index = vector.isRepeating ? 0 : i;
-		return SqlTimestamp.fromEpochMillis(
-				vector.time[index],
-				SqlTimestamp.isCompact(precision) ? 0 : vector.nanos[index] % 1_000_000);
+		Timestamp timestamp = new Timestamp(vector.time[index]);
+		timestamp.setNanos(vector.nanos[index]);
+		return SqlTimestamp.fromTimestamp(timestamp);
 	}
 }
diff --git a/flink-formats/flink-orc/src/test/java/org/apache/flink/orc/OrcColumnarRowSplitReaderTest.java b/flink-formats/flink-orc/src/test/java/org/apache/flink/orc/OrcColumnarRowSplitReaderTest.java
index 7d709c1d640..cf932063c8b 100644
--- a/flink-formats/flink-orc/src/test/java/org/apache/flink/orc/OrcColumnarRowSplitReaderTest.java
+++ b/flink-formats/flink-orc/src/test/java/org/apache/flink/orc/OrcColumnarRowSplitReaderTest.java
@@ -45,6 +45,7 @@ import java.io.File;
 import java.io.IOException;
 import java.math.BigDecimal;
 import java.sql.Date;
+import java.sql.Timestamp;
 import java.time.LocalDateTime;
 import java.util.ArrayList;
 import java.util.HashMap;
@@ -283,8 +284,11 @@ public class OrcColumnarRowSplitReaderTest {
 			for (int i = 0; i < rowSize - 1; i++) {
 				col0.vector[i] = i;
 				col1.vector[i] = i;
-				col2.time[i] = i * 1000;
-				col2.nanos[i] = i;
+
+				Timestamp timestamp = toTimestamp(i);
+				col2.time[i] = timestamp.getTime();
+				col2.nanos[i] = timestamp.getNanos();
+
 				col3.vector[i] = i;
 				col4.vector[i] = i;
 			}
@@ -304,7 +308,7 @@ public class OrcColumnarRowSplitReaderTest {
 		// second test read.
 		FileInputSplit split = createSplits(new Path(file), 1)[0];
 
-		long cnt = 0;
+		int cnt = 0;
 		Map<String, Object> partSpec = new HashMap<>();
 		partSpec.put("f5", true);
 		partSpec.put("f6", new Date(562423));
@@ -352,7 +356,7 @@ public class OrcColumnarRowSplitReaderTest {
 					Assert.assertFalse(row.isNullAt(3));
 					Assert.assertFalse(row.isNullAt(4));
 					Assert.assertEquals(
-							SqlTimestamp.fromEpochMillis(cnt * 1000, (int) cnt),
+							SqlTimestamp.fromTimestamp(toTimestamp(cnt)),
 							row.getTimestamp(0, 9));
 					Assert.assertEquals(cnt, row.getFloat(1), 0);
 					Assert.assertEquals(cnt, row.getDouble(2), 0);
@@ -381,6 +385,17 @@ public class OrcColumnarRowSplitReaderTest {
 		assertEquals(rowSize, cnt);
 	}
 
+	private static Timestamp toTimestamp(int i) {
+		return new Timestamp(
+						i + 1000,
+						(i % 12) + 1,
+						(i % 28) + 1,
+						i % 24,
+						i % 60,
+						i % 60,
+						i * 1_000 + i);
+	}
+
 	private OrcColumnarRowSplitReader createReader(
 			int[] selectedFields,
 			DataType[] fullTypes,
